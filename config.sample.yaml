# Kodelet Sample Configuration File
# This file shows all available configuration options with example values

# Logging Configuration
# Log level for the application (panic, fatal, error, warn, info, debug, trace)
log_level: "info"

# Log format for the application (json, text, fmt)
log_format: "json"

# LLM Configuration
# Provider to use (anthropic or openai)
provider: "anthropic"

# Model to use for LLM interactions
model: "claude-sonnet-4-20250514"

# Maximum tokens for responses
max_tokens: 8192

# Maximum tokens budget for thinking capability
thinking_budget_tokens: 4048

# Weak model to use for less complex tasks
weak_model: "claude-3-5-haiku-20241022"

# Maximum tokens for weak model responses
weak_model_max_tokens: 8192

# Model aliases for easier reference
# Allows using short names instead of full model identifiers
aliases:
  sonnet-4: "claude-sonnet-4-20250514"
  haiku-35: "claude-3-5-haiku-20241022"
  opus-4: "claude-opus-4-20250514"

# OpenAI specific settings
# Reasoning effort for OpenAI models (low, medium, high)
reasoning_effort: "medium"

# Security Configuration
# Command allow list for bash tool (empty means use default banned commands)
# When specified, only commands matching these patterns are allowed
# Supports wildcards: * matches any string
# Example patterns:
#   - "ls": exact match for ls command
#   - "ls *": ls with any arguments
#   - "npm *": any npm command
#   - "echo hello": exact echo hello command
allowed_commands: []
# allowed_commands:
#   - "ls *"
#   - "pwd"
#   - "echo *"
#   - "cat *"
#   - "grep *"
#   - "find *"
#   - "npm *"
#   - "yarn *"
#   - "git status"
#   - "git log *"


# Example OpenAI configuration (uncomment to use)
# provider: "openai"
# model: "gpt-4.1"
# max_tokens: 8192
# weak_model: "gpt-4.1-mini"
# weak_model_max_tokens: 4096
# reasoning_effort: "medium"

# Tracing Configuration
tracing:
  # Enable OpenTelemetry tracing (default: false)
  enabled: true

  # Sampling strategy (options: always, never, ratio)
  sampler: always

  # Sampling ratio when using ratio sampler (0.0-1.0)
  ratio: 1

# Environment variables can also be used to configure Kodelet:
# - KODELET_LOG_LEVEL: Overrides the log_level setting
# - KODELET_LOG_FORMAT: Overrides the log_format setting
# - KODELET_PROVIDER: Overrides the provider setting (anthropic, openai)
# - KODELET_MODEL: Overrides the model setting
# - KODELET_MAX_TOKENS: Overrides the max_tokens setting
# - KODELET_THINKING_BUDGET_TOKENS: Overrides the thinking_budget_tokens setting
# - KODELET_WEAK_MODEL: Overrides the weak_model setting
# - KODELET_WEAK_MODEL_MAX_TOKENS: Overrides the weak_model_max_tokens setting
# - KODELET_REASONING_EFFORT: Overrides the reasoning_effort setting (OpenAI)
# - KODELET_WEAK_REASONING_EFFORT: Overrides the weak_reasoning_effort setting (OpenAI)
# - KODELET_ALLOWED_COMMANDS: Comma-separated list of allowed command patterns
# - KODELET_TRACING_ENABLED: Enables/disables tracing
# - KODELET_TRACING_SAMPLER: Sets the sampling strategy
# - KODELET_TRACING_RATIO: Sets the sampling ratio
# - KODELET_ALIASES_*: Define individual aliases (e.g., KODELET_ALIASES_SONNET4=claude-sonnet-4-20250514)
#
# API Keys:
# - ANTHROPIC_API_KEY: Required when using the Anthropic provider
# - OPENAI_API_KEY: Required when using the OpenAI provider
#
# Standard OpenTelemetry environment variables are also supported:
# - OTEL_EXPORTER_OTLP_ENDPOINT: The endpoint to send telemetry data to
# - OTEL_EXPORTER_OTLP_HEADERS: Headers to use when sending telemetry data (for auth)
# - OTEL_RESOURCE_ATTRIBUTES: Additional resource attributes to include
