# Kodelet Sample Configuration File
# This file shows all available configuration options with example values

# Logging Configuration
# Log level for the application (panic, fatal, error, warn, info, debug, trace)
log_level: "info"

# Log format for the application (json, text, fmt)
log_format: "json"

# LLM Configuration
# Provider to use (anthropic or openai)
provider: "anthropic"

# Model to use for LLM interactions
model: "claude-sonnet-4-20250514"

# Maximum tokens for responses
max_tokens: 8192

# Maximum tokens budget for thinking capability
thinking_budget_tokens: 4048

# Weak model to use for less complex tasks
weak_model: "claude-3-5-haiku-20241022"

# Maximum tokens for weak model responses
weak_model_max_tokens: 8192

# Model aliases for easier reference
# Allows using short names instead of full model identifiers
aliases:
  sonnet-4: "claude-sonnet-4-20250514"
  haiku-35: "claude-3-5-haiku-20241022"
  opus-4: "claude-opus-4-20250514"

# Active profile selection (uncomment to activate a specific profile)
# profile: "premium"

# Profile definitions for different use cases
# Each profile can override any configuration setting
profiles:
  premium:
    model: "claude-opus-4-20250514"
    weak_model: "claude-sonnet-4-20250514"
    max_tokens: 16000
    weak_model_max_tokens: 8192
    thinking_budget_tokens: 8000

  fast:
    model: "haiku-35"
    weak_model: "haiku-35"
    max_tokens: 4096
    weak_model_max_tokens: 4096
    thinking_budget_tokens: 2000

  openai:
    provider: "openai"
    use_copilot: true
    model: "gpt-4.1"
    weak_model: "gpt-4.1-mini"
    max_tokens: 16000
    reasoning_effort: "medium"

  xai:
    provider: "openai"
    model: "grok-3"
    weak_model: "grok-3-mini"
    max_tokens: 16000
    reasoning_effort: "none"
    openai:
      preset: "xai"

  mix-n-match:
    provider: "anthropic"
    model: "sonnet-4"
    weak_model: "haiku-35"
    max_tokens: 16000
    
    subagent:
      provider: "openai"
      model: "o3"
      reasoning_effort: "high"
      allowed_tools: ["file_read", "glob_tool", "grep_tool", "thinking"]

# OpenAI specific settings
# Reasoning effort for OpenAI models (low, medium, high)
reasoning_effort: "medium"

# API Retry Configuration
# Controls retry behavior for API calls
# - Anthropic: Only 'attempts' is used (relies on SDK's built-in retry)
# - OpenAI: All fields are used (custom retry implementation)
retry:
  # Maximum number of retry attempts (default: 3)
  # Used by both Anthropic and OpenAI
  attempts: 3
  
  # Initial delay in milliseconds before first retry (default: 1000)
  # Used by OpenAI only
  initial_delay: 1000
  
  # Maximum delay in milliseconds between retries (default: 10000)
  # Used by OpenAI only
  max_delay: 10000
  
  # Backoff strategy: "fixed" or "exponential" (default: "exponential")
  # Used by OpenAI only
  backoff_type: "exponential"

# Security Configuration
# Command allow list for bash tool (empty means use default banned commands)
# When specified, only commands matching these patterns are allowed
# Supports wildcards: * matches any string
# Example patterns:
#   - "ls": exact match for ls command
#   - "ls *": ls with any arguments
#   - "npm *": any npm command
#   - "echo hello": exact echo hello command
allowed_commands: []
# allowed_commands:
#   - "ls *"
#   - "pwd"
#   - "echo *"
#   - "cat *"
#   - "grep *"
#   - "find *"
#   - "npm *"
#   - "yarn *"
#   - "git status"
#   - "git log *"

# Domain Filtering Configuration
# Path to file containing allowed domains for web_fetch tool (one domain per line)
# Supports exact matches (github.com) and glob patterns (*.github.com)
# If the file doesn't exist or is empty, all domains are allowed
# Localhost addresses (127.0.0.1, localhost, etc.) are always allowed
allowed_domains_file: "~/.kodelet/allowed_domains.txt"

# Tool Configuration
# Tools allowed for main agent (empty means use defaults)
# Meta tools (file_read, grep_tool, glob_tool, thinking) are always enabled for basic functionality
# Available tools: bash, file_read, file_write, file_edit, thinking, subagent, grep_tool, 
#                  glob_tool, todo_read, todo_write, web_fetch, image_recognition, 
#                  view_background_processes
allowed_tools: []
# allowed_tools:
#   - "bash"
#   - "file_read"      # Always enabled (meta tool)
#   - "file_write"
#   - "file_edit"
#   - "thinking"       # Always enabled (meta tool)
#   - "subagent"
#   - "grep_tool"      # Always enabled (meta tool)
#   - "glob_tool"      # Always enabled (meta tool)
#   - "todo_read"
#   - "todo_write"
#   - "web_fetch"
#   - "image_recognition"

# Commit Configuration
# Configure coauthor attribution for commit messages
commit:
  coauthor:
    # Enable or disable coauthor attribution (default: true)
    enabled: true
    # Coauthor name (default: "Kodelet")
    name: "Kodelet"
    # Coauthor email (default: "noreply@kodelet.com")  
    email: "noreply@kodelet.com"


# Example OpenAI configuration (uncomment to use)
# provider: "openai"
# model: "gpt-4.1"
# max_tokens: 8192
# weak_model: "gpt-4.1-mini"
# weak_model_max_tokens: 4096
# reasoning_effort: "medium"

# OpenAI-compatible API configuration
# Supports any OpenAI-compatible provider (xAI, Groq, Together AI, etc.)
openai:
  # Option 1: Use a built-in preset (recommended for popular providers)
  # preset: "xai"  # Built-in preset for xAI's Grok models

  # Option 2: Custom configuration (overrides preset if both are specified)
  # base_url: "https://api.x.ai/v1"  # Custom API endpoint
  # api_key_env_var: "XAI_API_KEY"   # Environment variable name for API key (defaults to OPENAI_API_KEY)
  # models:
  #   # Models that support reasoning capabilities (o1, o3, grok reasoning models, etc.)
  #   reasoning:
  #     - "grok-4-0709"
  #     - "grok-3-mini"
  #     - "grok-3-mini-fast"
  #   # Non-reasoning models (auto-populated if not specified)
  #   non_reasoning:
  #     - "grok-3"
  #     - "grok-3-fast"
  #     - "grok-2-vision-1212"
  # pricing:
  #   grok-4-0709:
  #     input: 0.000003         # $3 per million tokens
  #     output: 0.000015        # $15 per million tokens
  #     context_window: 256000  # 256k tokens
  #   grok-3:
  #     input: 0.000003         # $3 per million tokens
  #     output: 0.000015        # $15 per million tokens
  #     context_window: 131072  # 131k tokens
  #   # ... additional models

# Subagent Configuration
# Configure how subagents behave, including provider mix-and-match capabilities
# This allows main agent and subagents to use different providers/models
subagent:
  # Provider for subagents (can be different from main agent)
  # Example: Use GPT for subagents while main agent uses Claude
  # provider: "openai"
  
  # Model for subagents (typically a lighter/faster model)
  # model: "gpt-4o-mini"
  
  # Maximum tokens for subagent responses
  # max_tokens: 2048
  
  # OpenAI-specific: Reasoning effort for subagent (low, medium, high)
  # reasoning_effort: "low"
  
  # Anthropic-specific: Thinking budget for subagent
  # thinking_budget: 1024
  
  # Tools allowed for subagent (empty means use defaults)
  # Note: subagent tool is automatically excluded to prevent infinite recursion
  # Meta tools (file_read, grep_tool, glob_tool, thinking) are always enabled
  # allowed_tools:
  #   - "bash"
  #   - "file_read"      # Always enabled (meta tool)
  #   - "file_write"
  #   - "file_edit"
  #   - "grep_tool"      # Always enabled (meta tool)
  #   - "glob_tool"      # Always enabled (meta tool)
  #   - "thinking"       # Always enabled (meta tool)
  #   - "todo_read"
  #   - "todo_write"
  #   - "web_fetch"
  
  # OpenAI configuration for subagent (when using different provider)
  # openai:
  #   preset: "openai"
  #   # Or custom configuration:
  #   # base_url: "https://api.openai.com/v1"
  #   # pricing:
  #   #   gpt-4o-mini:
  #   #     input: 0.00015    # $0.15 per million tokens
  #   #     output: 0.0006    # $0.60 per million tokens
  #   #     context_window: 128000

# Example configurations for common scenarios:

# Scenario 1: Claude main agent with GPT subagents for cost optimization
# provider: "anthropic"
# model: "claude-sonnet-4-20250514"
# subagent:
#   provider: "openai"
#   model: "gpt-4o-mini"
#   max_tokens: 2048

# Scenario 2: GPT main agent with Claude subagents for specific tasks
# provider: "openai"
# model: "gpt-4.1"
# reasoning_effort: "high"
# subagent:
#   provider: "anthropic"
#   model: "claude-3-5-haiku-20241022"
#   max_tokens: 4096

# Scenario 3: Same provider, different models for performance
# provider: "anthropic"
# model: "claude-opus-4-20250514"
# subagent:
#   model: "claude-3-5-haiku-20241022"  # Faster model for subagent tasks
#   max_tokens: 2048

# Custom Tools Configuration
# Kodelet can discover and execute custom executable tools from specified directories
custom_tools:
  # Enable/disable custom tools discovery (default: true)
  enabled: true
  
  # Global custom tools directory (default: ~/.kodelet/tools)
  global_dir: "~/.kodelet/tools"
  
  # Local custom tools directory (default: ./kodelet-tools)
  local_dir: "./kodelet-tools"
  
  # Execution timeout for custom tools (default: 30s)
  timeout: 30s
  
  # Maximum output size for custom tools (default: 100KB)
  max_output_size: 102400

# Tracing Configuration
tracing:
  # Enable OpenTelemetry tracing (default: false)
  enabled: true

  # Sampling strategy (options: always, never, ratio)
  sampler: always

  # Sampling ratio when using ratio sampler (0.0-1.0)
  ratio: 1

# Environment variables can also be used to configure Kodelet:
# - KODELET_LOG_LEVEL: Overrides the log_level setting
# - KODELET_LOG_FORMAT: Overrides the log_format setting
# - KODELET_PROVIDER: Overrides the provider setting (anthropic, openai)
# - KODELET_MODEL: Overrides the model setting
# - KODELET_MAX_TOKENS: Overrides the max_tokens setting
# - KODELET_THINKING_BUDGET_TOKENS: Overrides the thinking_budget_tokens setting
# - KODELET_WEAK_MODEL: Overrides the weak_model setting
# - KODELET_WEAK_MODEL_MAX_TOKENS: Overrides the weak_model_max_tokens setting
# - KODELET_REASONING_EFFORT: Overrides the reasoning_effort setting (OpenAI)
# - KODELET_WEAK_REASONING_EFFORT: Overrides the weak_reasoning_effort setting (OpenAI)
# - KODELET_RETRY_ATTEMPTS: Overrides the retry.attempts setting
# - KODELET_RETRY_INITIAL_DELAY: Overrides the retry.initial_delay setting (milliseconds)
# - KODELET_RETRY_MAX_DELAY: Overrides the retry.max_delay setting (milliseconds)
# - KODELET_RETRY_BACKOFF_TYPE: Overrides the retry.backoff_type setting (fixed, exponential)
# - KODELET_ALLOWED_COMMANDS: Comma-separated list of allowed command patterns
# - KODELET_ALLOWED_TOOLS: Comma-separated list of allowed tools for main agent
# - KODELET_TRACING_ENABLED: Enables/disables tracing
# - KODELET_TRACING_SAMPLER: Sets the sampling strategy
# - KODELET_TRACING_RATIO: Sets the sampling ratio
# - KODELET_ALIASES_*: Define individual aliases (e.g., KODELET_ALIASES_SONNET4=claude-sonnet-4-20250514)
# - KODELET_COMMIT_COAUTHOR_ENABLED: Enable/disable coauthor attribution in commits
# - KODELET_COMMIT_COAUTHOR_NAME: Name for coauthor attribution
# - KODELET_COMMIT_COAUTHOR_EMAIL: Email for coauthor attribution
#
# API Keys:
# - ANTHROPIC_API_KEY: Required when using the Anthropic provider
# - OPENAI_API_KEY: Required when using the OpenAI provider (default)
# - XAI_API_KEY: Required when using the xAI preset
# - OPENAI_API_BASE: Custom OpenAI API endpoint (overrides config base_url)
# Note: The API key environment variable can be customized using the api_key_env_var setting
#
# Standard OpenTelemetry environment variables are also supported:
# - OTEL_EXPORTER_OTLP_ENDPOINT: The endpoint to send telemetry data to
# - OTEL_EXPORTER_OTLP_HEADERS: Headers to use when sending telemetry data (for auth)
# - OTEL_RESOURCE_ATTRIBUTES: Additional resource attributes to include
